{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharique\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data in df and removing target variable quality and loading in y\n",
    "# This is the same dataset used for Decision Tree\n",
    "\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
    "y = df.pop('quality')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 11 columns):\n",
      "fixed acidity           4898 non-null float64\n",
      "volatile acidity        4898 non-null float64\n",
      "citric acid             4898 non-null float64\n",
      "residual sugar          4898 non-null float64\n",
      "chlorides               4898 non-null float64\n",
      "free sulfur dioxide     4898 non-null float64\n",
      "total sulfur dioxide    4898 non-null float64\n",
      "density                 4898 non-null float64\n",
      "pH                      4898 non-null float64\n",
      "sulphates               4898 non-null float64\n",
      "alcohol                 4898 non-null float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 421.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(df, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic regression on the unscaled train data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Logistic Regression: 0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "y_pred = lr.predict(test)\n",
    "print('Accuracy score for Logistic Regression:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to parameterize the Random Forest tree hyper-parameters \n",
    "\n",
    "### Run in loop for different values to identify the best value for hyperparameters and use that value in the final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(train, test, y_train, y_test,  max_depth = None , \n",
    "                n_estimators = 10, max_features = 'auto', min_samples_split = 2,scaler = None):\n",
    "    if scaler:\n",
    "        train = scaler.fit_transform(train)\n",
    "        test = scaler.fit_transform(test)        \n",
    "    RF = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, \n",
    "                                random_state = 42, max_features = max_features,\n",
    "                               min_samples_split = min_samples_split)\n",
    "    RF.fit(train, y_train)\n",
    "    y_pred = RF.predict(test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy score: : 0.6428571428571429\n",
      "baseline accuracy score with scaler: 0.6183673469387755\n"
     ]
    }
   ],
   "source": [
    "print('baseline accuracy score: ',end= \": \")\n",
    "fit_predict(train,test,y_train,y_test)\n",
    "print('baseline accuracy score with scaler', end = ': ')\n",
    "fit_predict(train,test,y_train,y_test,scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in loop for different hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using n_estimators = 20: 0.6591836734693878\n",
      "Accuracy score using n_estimators = 30: 0.6663265306122449\n",
      "Accuracy score using n_estimators = 40: 0.6744897959183673\n",
      "Accuracy score using n_estimators = 50: 0.6816326530612244\n",
      "Accuracy score using n_estimators = 60: 0.6816326530612244\n",
      "Accuracy score using n_estimators = 70: 0.6846938775510204\n",
      "Accuracy score using n_estimators = 80: 0.6877551020408164\n",
      "Accuracy score using n_estimators = 90: 0.686734693877551\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in range(20,100,10):\n",
    "    print('Accuracy score using n_estimators =', n_estimators, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_depth = 1: 0.44081632653061226\n",
      "Accuracy score using max_depth = 2: 0.4897959183673469\n",
      "Accuracy score using max_depth = 3: 0.49387755102040815\n",
      "Accuracy score using max_depth = 4: 0.5051020408163265\n",
      "Accuracy score using max_depth = 5: 0.5244897959183673\n",
      "Accuracy score using max_depth = 6: 0.5357142857142857\n",
      "Accuracy score using max_depth = 7: 0.563265306122449\n",
      "Accuracy score using max_depth = 8: 0.5826530612244898\n",
      "Accuracy score using max_depth = 9: 0.5959183673469388\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(1,10):\n",
    "    print('Accuracy score using max_depth =', max_depth, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_depth = max_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_features = 0.1: 0.6969387755102041\n",
      "Accuracy score using max_features = 0.2: 0.7040816326530612\n",
      "Accuracy score using max_features = 0.30000000000000004: 0.7020408163265306\n",
      "Accuracy score using max_features = 0.4: 0.6948979591836735\n",
      "Accuracy score using max_features = 0.5: 0.6969387755102041\n",
      "Accuracy score using max_features = 0.6: 0.6908163265306122\n",
      "Accuracy score using max_features = 0.7000000000000001: 0.6969387755102041\n",
      "Accuracy score using max_features = 0.8: 0.6989795918367347\n",
      "Accuracy score using max_features = 0.9: 0.6918367346938775\n",
      "Accuracy score using max_features = 1.0: 0.7020408163265306\n"
     ]
    }
   ],
   "source": [
    "for max_features in np.linspace(0.1,1,10):\n",
    "    print('Accuracy score using max_features =', max_features, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = max_features,max_depth = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using min_samples_split = 2: 0.7040816326530612\n",
      "Accuracy score using min_samples_split = 3: 0.7193877551020408\n",
      "Accuracy score using min_samples_split = 4: 0.7040816326530612\n",
      "Accuracy score using min_samples_split = 5: 0.6938775510204082\n",
      "Accuracy score using min_samples_split = 6: 0.6938775510204082\n",
      "Accuracy score using min_samples_split = 7: 0.6857142857142857\n",
      "Accuracy score using min_samples_split = 8: 0.6806122448979591\n",
      "Accuracy score using min_samples_split = 9: 0.6714285714285714\n"
     ]
    }
   ],
   "source": [
    "for min_samples_split in range(2,10):\n",
    "    print('Accuracy score using min_samples_split =', min_samples_split, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=min_samples_split\n",
    "               ,max_depth = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned accuracy score: 0.6806122448979591\n",
      "tuned accuracy score with scaler: 0.6806122448979591\n"
     ]
    }
   ],
   "source": [
    "print('tuned accuracy score', end = ': ')\n",
    "fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=3,max_depth = 18)\n",
    "print('tuned accuracy score with scaler', end = ': ')\n",
    "\n",
    "fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=3,\n",
    "            max_depth = 18,scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the new accuracy with the original value \n",
    "\n",
    "#### NOTE: These accuracy values will be slightly different in your run based on data samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement is 39.88 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.514285714286\n",
    "best_score = 0.7193877551020408\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement is {} %'.format(improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement compare to non tuned model is 11.9 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.6428571428571429\n",
    "best_score = 0.7193877551020408\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement compare to non tuned model is {} %'.format(improvement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
