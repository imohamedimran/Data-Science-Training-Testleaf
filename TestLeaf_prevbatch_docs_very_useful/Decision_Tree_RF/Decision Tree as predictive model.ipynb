{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data in df and removing target variable quality and loading in y\n",
    "\n",
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
    "y = df.pop('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 11 columns):\n",
      "fixed acidity           4898 non-null float64\n",
      "volatile acidity        4898 non-null float64\n",
      "citric acid             4898 non-null float64\n",
      "residual sugar          4898 non-null float64\n",
      "chlorides               4898 non-null float64\n",
      "free sulfur dioxide     4898 non-null float64\n",
      "total sulfur dioxide    4898 non-null float64\n",
      "density                 4898 non-null float64\n",
      "pH                      4898 non-null float64\n",
      "sulphates               4898 non-null float64\n",
      "alcohol                 4898 non-null float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 421.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in df.columns:\n",
    "#    df[i] = df[i].fillna(np.mean(df[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(df, y, test_size = 0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression on the unscaled train data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic regression: 0.5255102040816326\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "y_pred = lr.predict(test)\n",
    "print('Accuracy score of Logistic regression:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   3   3   0   0   0]\n",
      " [  0   0  16  10   0   0   0]\n",
      " [  0   0 151 129   0   0   0]\n",
      " [  0   0  91 355   6   0   0]\n",
      " [  0   0   6 163   9   0   0]\n",
      " [  0   0   2  28   6   0   0]\n",
      " [  0   0   0   2   0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       0.00      0.00      0.00        26\n",
      "          5       0.56      0.54      0.55       280\n",
      "          6       0.51      0.79      0.62       452\n",
      "          7       0.43      0.05      0.09       178\n",
      "          8       0.00      0.00      0.00        36\n",
      "          9       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.48      0.53      0.46       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to parameterize the decision tree hyper-parameters \n",
    "\n",
    "### Run in loop for different values to identify the best value for hyperparameters and use that value in the final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(train, test, y_train, y_test, scaler, max_depth, \n",
    "                criterion = 'entropy', max_features = 1, min_samples_split = 4):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    test_scaled = scaler.fit_transform(test)        \n",
    "    dt = DecisionTreeClassifier(criterion = criterion, max_depth=max_depth, \n",
    "                                random_state=42, max_features=max_features,\n",
    "                               min_samples_split=min_samples_split)\n",
    "    dt.fit(train_scaled, y_train)\n",
    "    y_pred = dt.predict(test_scaled)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max depth tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_depth = 1: 0.46122448979591835\n",
      "Accuracy score using max_depth = 2: 0.46122448979591835\n",
      "Accuracy score using max_depth = 3: 0.4846938775510204\n",
      "Accuracy score using max_depth = 4: 0.4642857142857143\n",
      "Accuracy score using max_depth = 5: 0.5010204081632653\n",
      "Accuracy score using max_depth = 6: 0.45\n",
      "Accuracy score using max_depth = 7: 0.47346938775510206\n",
      "Accuracy score using max_depth = 8: 0.4816326530612245\n",
      "Accuracy score using max_depth = 9: 0.5051020408163265\n",
      "Accuracy score using max_depth = 10: 0.5081632653061224\n",
      "Accuracy score using max_depth = 11: 0.5112244897959184\n",
      "Accuracy score using max_depth = 12: 0.5418367346938775\n",
      "Accuracy score using max_depth = 13: 0.5377551020408163\n",
      "Accuracy score using max_depth = 14: 0.5448979591836735\n",
      "Accuracy score using max_depth = 15: 0.5489795918367347\n",
      "Accuracy score using max_depth = 16: 0.5173469387755102\n",
      "Accuracy score using max_depth = 17: 0.5244897959183673\n",
      "Accuracy score using max_depth = 18: 0.5255102040816326\n",
      "Accuracy score using max_depth = 19: 0.5785714285714286\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    print('Accuracy score using max_depth =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max features = 0.1: 0.5775510204081633\n",
      "Accuracy score using max features = 0.2: 0.6081632653061224\n",
      "Accuracy score using max features = 0.30000000000000004: 0.6081632653061224\n",
      "Accuracy score using max features = 0.4: 0.5959183673469388\n",
      "Accuracy score using max features = 0.5: 0.6061224489795919\n",
      "Accuracy score using max features = 0.6: 0.5806122448979592\n",
      "Accuracy score using max features = 0.7000000000000001: 0.6030612244897959\n",
      "Accuracy score using max features = 0.8: 0.5724489795918367\n",
      "Accuracy score using max features = 0.9: 0.576530612244898\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    print('Accuracy score using max features =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), max_depth = 18, max_features=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min samples split tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using min samples split = 2: 0.5908163265306122\n",
      "Accuracy score using min samples split = 3: 0.5530612244897959\n",
      "Accuracy score using min samples split = 4: 0.563265306122449\n",
      "Accuracy score using min samples split = 5: 0.5642857142857143\n",
      "Accuracy score using min samples split = 6: 0.5428571428571428\n",
      "Accuracy score using min samples split = 7: 0.5112244897959184\n",
      "Accuracy score using min samples split = 8: 0.5377551020408163\n",
      "Accuracy score using min samples split = 9: 0.5510204081632653\n",
      "Accuracy score using min samples split = 10: 0.5540816326530612\n",
      "Accuracy score using min samples split = 11: 0.5377551020408163\n",
      "Accuracy score using min samples split = 12: 0.5418367346938775\n",
      "Accuracy score using min samples split = 13: 0.5591836734693878\n",
      "Accuracy score using min samples split = 14: 0.5265306122448979\n",
      "Accuracy score using min samples split = 15: 0.5244897959183673\n",
      "Accuracy score using min samples split = 16: 0.5153061224489796\n",
      "Accuracy score using min samples split = 17: 0.5275510204081633\n",
      "Accuracy score using min samples split = 18: 0.5489795918367347\n",
      "Accuracy score using min samples split = 19: 0.5530612244897959\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 20):\n",
    "    print('Accuracy score using min samples split =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, max_features=0.2, min_samples_split=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using criterion = gini: 0.5785714285714286\n",
      "Accuracy score using criterion = entropy: 0.5908163265306122\n"
     ]
    }
   ],
   "source": [
    "for i in ['gini', 'entropy']:\n",
    "    print('Accuracy score using criterion =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.2, min_samples_split=2, criterion = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Polynomial features of the train/test data with various degrees and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_poly(train,test,degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    train_poly = poly.fit_transform(train)\n",
    "    test_poly = poly.fit_transform(test)\n",
    "    return train_poly,test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial degree 1\n",
      "0.6193877551020408\n",
      "----------\n",
      "Polynomial degree 2\n",
      "0.5591836734693878\n",
      "----------\n",
      "Polynomial degree 3\n",
      "0.5428571428571428\n",
      "----------\n",
      "Polynomial degree 4\n",
      "0.5387755102040817\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for degree in [1,2,3,4]:\n",
    "    train_poly, test_poly = create_poly(train, test, degree)\n",
    "    print('Polynomial degree',degree)\n",
    "    fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "    print(10*'-')\n",
    "    \n",
    "train_poly, test_poly = create_poly(train, test, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new features and run the model without/with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional feature engineering:\n",
      "0.5816326530612245\n",
      "0.5520408163265306\n"
     ]
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    df['eng1'] = df['fixed acidity'] * df['pH']\n",
    "    df['eng2'] = df['total sulfur dioxide'] / df['free sulfur dioxide']\n",
    "    df['eng3'] = df['sulphates'] / df['chlorides']\n",
    "    df['eng4'] = df['chlorides'] / df['sulphates']\n",
    "    return df\n",
    "\n",
    "train = feat_eng(train)\n",
    "test = feat_eng(test)\n",
    "\n",
    "print('Additional feature engineering:')\n",
    "\n",
    "fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "\n",
    "train_poly, test_poly = create_poly(train, test, 2)\n",
    "\n",
    "fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the new accuracy with the Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement is 17.86 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.5255102040816326\n",
    "best_score = 0.6193877551020408\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement is {} %'.format(improvement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
